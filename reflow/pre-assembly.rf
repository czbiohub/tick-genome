// This workflow performs the following steps:
// 1. Run FastQC on R1 and R2
// 2. Remove Nextera adapters using AdapterRemoval
// 3. Remove PhiX sequences usinb BBduk
// 4. Run FastQC on Adapter-trimmed, PhiX-removed reads
// 5. Get kmer distributions and estimated genome size from R1 and R2
// 6. Remove super-high and super-low coverage regions to perform "Digital Normalization"
// 7. Get kmer distributions on digitial normalization data
// 8. Run FastQC on digitally normalized data

param (
    // S3 path to a single fastq(.gz) file
    read1 string

    // S3 path to a single fastq(.gz) file
    read2 string

    // name of the sample
    id string

    // S3 folder to put all the fastqs and reports
    output string

    // two-columnm, whitespace-separated file containing adapters. 
    // First column is R1 adapters, second is R2 adapters
    adapter_list string

    // Minimum read length after trimming
    minlength = 135

    // 
    ksize = 32
)

// System modules
val dirs = make("$/dirs")


val adapter_removal = make("./adapter_removal.rf")
val fastqc = make("./fastqc.rf")
val bbduk = make("./bbduk.rf")
val kat = make("./kat.rf")
val khmer = make("./khmer.rf")
val utils = make("./utils.rf")
val fastp = make("./fastp.rf")


val r1 = file(read1)
val r2 = file(read2)

val adapter_file = file(adapter_list)

status := "_pre_trimming"

val r1_fastqc_reports = fastqc.FastQC(r1, id + "_R1" + status)
val r2_fastqc_reports = fastqc.FastQC(r2, id + "_R2" + status)

// -- Remove Illumina Nextera Adapters --- //
val adapter_removed = adapter_removal.AdapterRemoval(r1, r2, id, adapter_file, minlength)

// Extract R1, R2 read pairs from output directory
val (r1_adapter_trimmed, _) = dirs.Pick(adapter_removed, "*_R1_*.fastq.gz")
val (r2_adapter_trimmed, _) = dirs.Pick(adapter_removed, "*_R2_*.fastq.gz")

// --- Remove Poly-G (known NovaSeq issue) ---
val polyg_removed = fastp.TrimPolyG(r1_adapter_trimmed, r2_adapter_trimmed, id, minlength)

// Extract R1, R2 read pairs from output directory
val (r1_polyg_removed, _) = dirs.Pick(polyg_removed, "*_R1_*.fastq.gz")
val (r2_polyg_removed, _) = dirs.Pick(polyg_removed, "*_R2_*.fastq.gz")

// -- Remove PhiX Sequences --- //
val phix_trimmed = bbduk.PhiXTrimming(r1_polyg_removed, r2_polyg_removed, id, minlength)

// Extract R1, R2 read pairs from output directory
val (r1_phix_trimmed, _) = dirs.Pick(phix_trimmed, "*R1*.fastq.gz")
val (r2_phix_trimmed, _) = dirs.Pick(phix_trimmed, "*R2*.fastq.gz")

// Create list of reads
status := "_post-trimming"
val reads_phix_trimmed = ["_R1" + status: r1_phix_trimmed, "_R2" + status: r2_phix_trimmed]


// Do FastQC AGAIN after trimming to make sure
val fastqc_post_trimming = [
    fastqc.FastQC(reads, id + read_number) | (read_number, reads) <- reads_phix_trimmed]

// Get kmer histogram before trimming
val hist_pre_normalization = [
    kat.Hist(reads, id + read_number, ksize) | (read_number, reads) <- reads_phix_trimmed]
val khmer_hist_pre_normalization = [
    (id + read_number + "_khmer.histogram", khmer.Hist(reads, ksize)) | (read_number, reads) <- reads_phix_trimmed]

// -- Perform Digital Normalization --
// -- Remove reads with too-high or too-low abundance -- //
//   Why?
//   - high-abundance kmers mess up assembly
//   - low-abundance kmers are probably erroneous
val normalized = khmer.NormalizeHighCoverage(
    r1_phix_trimmed, r2_phix_trimmed, ksize)

// -- Get kmer distribution histograms after normalization --- //
status := "_post-digital_normalization"
val reads_normalized = ["_R1" + status: normalized.r1_normalized, 
    "_R2" + status: normalized.r2_normalized]
val hist_post_normalization = [
    kat.Hist(reads, id + read_number, ksize) | (read_number, reads) <- reads_normalized]
val khmer_hist_post_normalization = [
    (id + read_number + "_khmer.histogram", khmer.Hist(reads, ksize)) | (read_number, reads) <- reads_normalized]

val renamed = [(id + read_number + ".fastq.gz", reads) | (read_number, reads) <- reads_phix_trimmed]
val normalized_dir = dirs.Make(map(renamed))

// Do FastQC AGAIN after normalization to make sure
val fastqc_post_normalization = [
    fastqc.FastQC(reads, id + read_number) | (read_number, reads) <- reads_normalized]

val khmer_histograms = khmer_hist_pre_normalization + khmer_hist_post_normalization
val khmer_dir = dirs.Make(map(khmer_histograms))

// // -- Compute sourmash signature -- //
// signatures_unnormalized := sourmash.Compute(reads_human_removed)
// signatures_normalized := sourmash.Compute(reads_normalized)

// // -- Check against sourmash RefSeq and GenBank databases -- //
// val search_refseq_genbank_unnormalized := sourmash.Search(signatures_unnormalized)
// val search_refseq_genbank_normalized := sourmash.Search(signatures_normalized, 
//     track_abundance=false)


output_dirs := [r1_fastqc_reports, r2_fastqc_reports, adapter_removed, 
    phix_trimmed, normalized_dir, khmer_dir] + fastqc_post_trimming + hist_pre_normalization + hist_post_normalization + fastqc_post_normalization
    // human_removed, 
    // kat_hist_pre_normalization, normalized, kat_hist_pre_normalization, 
    // re_paired, signatures, search_refseq_genbank]


@requires(cpu := 2)
val Main = 
    [dirs.Copy(d, output) | d <- output_dirs]
