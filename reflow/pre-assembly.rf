// This workflow performs the following steps:
// 1. Run FastQC on R1 and R2
// 2. Remove Nextera adapters using AdapterRemoval
// 3. Remove PhiX sequences usinb BBduk
// 4. Run FastQC on Adapter-trimmed, PhiX-removed reads
// 5. Get kmer distributions and estimated genome size from R1 and R2
// 6. Remove super-high and super-low coverage regions to perform "Digital Normalization"
// 7. Get kmer distributions on digitial normalization data
// 8. Run FastQC on digitally normalized data

param (
    // S3 path to a single fastq.gz file
    read1 string

    // S3 path to a single fastq.gz file
    read2 string

    // name of the sample
    id string

    // S3 folder to put all the fastqs and reports
    output string

    // two-columnm, whitespace-separated file containing adapters. 
    // First column is R1 adapters, second is R2 adapters
    adapter_list string

    // reference genome fasta.gz files, pipe-separated
    references string

    // pipe-separated unique ids for the reference names
    references_ids string

    // Minimum read length after trimming
    minlength = 135

    // kmer size to use for khmer trimming and histograms
    ksize = 32

)

// System modules
val dirs = make("$/dirs")
val strings = make("$/strings")


val adapter_removal = make("./adapter_removal.rf")
val fastqc = make("./fastqc.rf")
val bbduk = make("./bbduk.rf")
val kat = make("./kat.rf")
val khmer = make("./khmer.rf")
val kmergenie = make("./kmergenie.rf")
val merge_paired = make("./merge_paired.rf")
val utils = make("./utils.rf")
val fastp = make("./fastp.rf")
val bwa = make("./bwa.rf")


val r1 = file(read1)
val r2 = file(read2)

val reference_fastas = utils.SplitByPipe(references)
val reference_ids = strings.Split(references_ids, "|")
val reference_map = map(zip(reference_ids, reference_fastas))

val adapter_file = file(adapter_list)

// Create map of read number + status for each read
val reads_pre_trimming = utils.MakeNamedStatusReads(
        r1, r2, id, "_pre_trimming")

val pre_trimming_fastqc = [fastqc.FastQC(read, name) | (name, read) <- reads_pre_trimming]

// -- Remove Illumina Nextera Adapters --- //
val adapter_removed = adapter_removal.AdapterRemoval(r1, r2, id, 
    adapter_file, minlength)

// --- Remove Poly-G (known NovaSeq issue) ---
val polyg_removed = fastp.TrimPolyG(adapter_removed.r1, adapter_removed.r2, 
    id, minlength)

// -- Remove PhiX Sequences --- //
val phix_trimmed = bbduk.PhiXTrimming(polyg_removed.r1, polyg_removed.r2, 
    id, minlength)

// -- Merge paired-end reads that have overlapping sequence -- //
val merged = merge_paired.Run(phix_trimmed.r1, phix_trimmed.r2, id)


status := "_post-trimming"
// Use kmergenie to estimate best kmer size
val kmergenie_trimmed = kmergenie.Run(
    phix_trimmed.r1, phix_trimmed.r2, id + status)

// Aligned trimmed to reference
// val reference_aligned_trimmed = [
//     bwa.Align(phix_trimmed.r1, 
//         phix_trimmed.r2, id + status, 
//         fasta, ref_id) | 
//         (ref_id, fasta) <- reference_map]

// Create map of read number + status for each read
val reads_phix_trimmed = utils.MakeNamedStatusReads(
        phix_trimmed.r1, phix_trimmed.r2, id, status)


// Do FastQC AGAIN after trimming to make sure
val fastqc_post_trimming = [
    fastqc.FastQC(reads, name) | (name, reads) <- reads_phix_trimmed]

// Get kmer histogram before trimming

val khmer_hist_pre_normalization = [
    (name + "_khmer.histogram", khmer.Hist(reads, ksize)) | (name, reads) <- reads_phix_trimmed]

// -- Perform Digital Normalization --
// -- Remove reads with too-high or too-low abundance -- //
//   Why?
//   - high-abundance kmers mess up assembly
//   - low-abundance kmers are probably erroneous
val normalized = khmer.NormalizeHighCoverage(
    phix_trimmed.r1, phix_trimmed.r2, ksize)

// -- Get kmer distribution histograms after normalization --- //
status := "_post-digital_normalization"
val reads_normalized = ["_R1" + status: normalized.r1_normalized, 
    "_R2" + status: normalized.r2_normalized]
val khmer_hist_post_normalization = [
    (id + read_number + "_khmer.histogram", khmer.Hist(reads, ksize)) | (read_number, reads) <- reads_normalized]

val renamed = [(id + read_number + ".fastq.gz", reads) | (read_number, reads) <- reads_phix_trimmed]
val normalized_dir = dirs.Make(map(renamed))

// Do FastQC AGAIN after normalization to make sure
val fastqc_post_normalization = [
    fastqc.FastQC(reads, id + read_number) | (read_number, reads) <- reads_normalized]

val khmer_histograms = khmer_hist_pre_normalization + khmer_hist_post_normalization
val khmer_dir = dirs.Make(map(khmer_histograms))

// Use kmergenie to estimate best kmer size
val kmergenie_normalized = kmergenie.Run(
    phix_trimmed.r1, phix_trimmed.r2, id + status)

// Align digitially normalized to reference
// val reference_aligned_normalized = [
//     bwa.Align(normalized.r1_normalized, 
//         normalized.r2_normalized, id + status, 
//         fasta, ref_id) | 
//         (ref_id, fasta) <- reference_map]

output_dirs := [adapter_removed.reports, 
                polyg_removed.reports,
    phix_trimmed.reports, 
    merged.reports,
    kmergenie_trimmed, 
    kmergenie_normalized,
    normalized_dir, khmer_dir] + 
    pre_trimming_fastqc +
        fastqc_post_trimming + 
        fastqc_post_normalization //+ 
        // reference_aligned_trimmed +
        // reference_aligned_normalized



@requires(cpu := 2)
val Main = 
    [dirs.Copy(d, output) | d <- output_dirs]
