param (
    // S3 path to a single fastq(.gz) file
    read1 string

    // S3 path to a single fastq(.gz) file
    read2 string

    // name of the sample
    id string

    // S3 folder to put all the fastqs and reports
    output string

    // two-columnm, whitespace-separated file containing adapters. 
    // First column is R1 adapters, second is R2 adapters
    adapter_list string

    // Minimum read length after trimming
    minlength = 135

    // 
    ksize = 32
)

// System modules
val dirs = make("$/dirs")


val adapter_removal = make("./adapter_removal.rf")
val fastqc = make("./fastqc.rf")
val bbduk = make("./bbduk.rf")
val idseq = make("./idseq.rf")
val kat = make("./kat.rf")


val r1 = file(read1)
val r2 = file(read2)

val adapter_file = file(adapter_list)

val r1_fastqc_reports = fastqc.FastQC(r1, id + "_R1")
val r2_fastqc_reports = fastqc.FastQC(r2, id + "_R2")

// -- Remove Illumina Nextera Adapters --- //
val adapter_removed = adapter_removal.AdapterRemoval(r1, r2, id, adapter_file, minlength)

// Extract R1, R2 read pairs from output directory
val (r1_adapter_trimmed, _) = dirs.Pick(adapter_removed, "*_R1_adapterremoval_trimmed.fastq.gz")
val (r2_adapter_trimmed, _) = dirs.Pick(adapter_removed, "*_R2_adapterremoval_trimmed.fastq.gz")

// -- Remove PhiX Sequences --- //
val phix_trimmed = bbduk.PhiXTrimming(r1_adapter_trimmed, r2_adapter_trimmed, id, minlength)

// Extract R1, R2 read pairs from output directory
val (r1_phix_trimmed, _) = dirs.Pick(phix_trimmed, "*_R1_bbduk_phix_trimmed.fastq.gz")
val (r2_phix_trimmed, _) = dirs.Pick(phix_trimmed, "*_R2_bbduk_phix_trimmed.fastq.gz")

// -- Remove Human Sequences --- //
val human_removed = idseq.RemoveHuman(r1_phix_trimmed, r2_phix_trimmed, id)

// Extract R1 and R2
val (r1_human_removed, _) = dirs.Pick(human_removed, "*_unmapped_R1.fastq.gz")
val (r2_human_removed, _) = dirs.Pick(human_removed, "*_unmapped_R2.fastq.gz")

// -- Get kmer distribution histograms before normalization --- //
val reads_human_removed = [r1_human_removed, r2_human_removed]
val hist_pre_normalization = [khmer.Hist(reads) | reads <- reads_human_removed]

// -- Perform Digital Normalization --
// -- Remove reads with too-high or too-low abundance -- //
//   Why?
//   - high-abundance kmers mess up assembly
//   - low-abundance kmers are probably erroneous
val (r1_normalized, r2_normalized) = khmer.NormalizeHighCoverage(
    r1_human_removed, r2_human_removed, ksize)

// -- Get kmer distribution histograms after normalization --- //
val reads_normalized = [r1_normalized, r2_normalized]
val hist_post_normalization = [khmer.Hist(reads) | reads <- reads_normalized]


// // -- Compute sourmash signature -- //
// signatures_unnormalized := sourmash.Compute(reads_human_removed)
// signatures_normalized := sourmash.Compute(reads_normalized)

// // -- Check against sourmash RefSeq and GenBank databases -- //
// val search_refseq_genbank_unnormalized := sourmash.Search(signatures_unnormalized)
// val search_refseq_genbank_normalized := sourmash.Search(signatures_normalized, 
//     track_abundance=false)



output_dirs := [r1_fastqc_reports, r2_fastqc_reports, adapter_removed, 
    phix_trimmed, human_removed]
    // human_removed, 
    // kat_hist_pre_normalization, normalized, kat_hist_pre_normalization, 
    // re_paired, signatures, search_refseq_genbank]


@requires(cpu := 2)
val Main = [dirs.Copy(d, output) | d <- output_dirs]
